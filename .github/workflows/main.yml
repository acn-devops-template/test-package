name: main

on:
  workflow_dispatch:
  # pull_request:
  #   types: [opened, reopened]
  #   branches:
  #     - main

jobs:
  cd-pipeline:
    runs-on: ubuntu-latest

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      DATABRICKS_JOBS_API_VERSION: 2.1 # Use Job API 2.1 instead of 2.0
      GH_TOKEN: ${{ secrets.GH_PAT }}
      REPOSITORY_USERNAME: smith.simargool
      REPOSITORY_PASSWORD: ${{ secrets.AZURE_ARTIFACTS_PAT }}
      AZURE_DEVOPS_EXT_PAT: ${{ secrets.AZURE_ARTIFACTS_PAT }}

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - uses: fregante/setup-git-user@v1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install pip & pex
        run: |
          pip install --upgrade pip
          pip install pex

      - name: Install poetry
        uses: snok/install-poetry@v1

      - name: Install dependencies and project
        run: |
          poetry config http-basic.pk_repo_prod gh_actions ${{ secrets.AZURE_ARTIFACTS_PAT }}
          poetry install -v --without test
          poetry run pip list --format=freeze --exclude=pip > requirements.txt

      - name: Semantic Release Prerelease
        run: |
          poetry run semantic-release publish --prerelease -D repository_url=${{ secrets.AZURE_ARTIFACTS_UPLOAD }} -v DEBUG

      - name: import nb
        run: |
          pk_name=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.name)
          pk_version=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.version)
          poetry run databricks workspace mkdirs "/Users/smith.simargool@scb.co.th/$pk_name"
          poetry run databricks workspace import -l PYTHON -o ./conf/py_nb.py /Users/smith.simargool@scb.co.th/$pk_name/dev

      - name: create dlt pipeline
        run: |
          poetry run python conf/dlt_pipeline.py --host ${{secrets.DATABRICKS_HOST}} --token ${{secrets.DATABRICKS_TOKEN}} --json_path ./conf/orchestrator/dlt/create-pipeline.json --mode dev

      - name: Job deployment
        run: |
          poetry run dbx configure --enable-inplace-jinja-support
          poetry run dbx deploy --deployment-file=./conf/orchestrator/dbx/deployment.yml.j2 --workflows='dlt-from-remote-dev' --no-package --assets-only
          poetry run dbx launch --from-assets --trace dlt-from-remote-dev

      - name: Semantic Release
        run: |
          poetry run semantic-release publish -D repository_url=${{ secrets.AZURE_ARTIFACTS_UPLOAD_PROD }} -D remove_dist=false -v DEBUG

      - name: Build and Upload PEX
        run: |
          pk_name=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.name)
          pk_version=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.version)
          pk_description=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.description)
          pex -v --requirement=requirements.txt --sources-directory=. --output-file=dist/pex/${pk_name}_${pk_version}.pex --entry-point datax.generic_pipeline.cardx_credit_card -f dist -i https://${{ secrets.AZURE_ARTIFACTS_PAT }}@${{ secrets.PKGS_DL_PROD }} --disable-cache
          poetry run az extension add --name azure-devops
          poetry run az artifacts universal publish --organization https://dev.azure.com/datax-tmp/ --project="package_repo" --scope project --feed pk-repo-prod --name ${pk_name}_pex --version $pk_version --description $pk_description --path dist/pex/

      - name: import nb prod
        run: |
          pk_name=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.name)
          pk_version=$(poetry run toml get --toml-path ./pyproject.toml tool.poetry.version)
          poetry run databricks workspace import -l PYTHON -o ./conf/py_nb_prod.py /Users/smith.simargool@scb.co.th/$pk_name/prod

      - name: create prod dlt pipeline
        run: |
          poetry run python conf/dlt_pipeline.py --host ${{secrets.DATABRICKS_HOST}} --token ${{secrets.DATABRICKS_TOKEN}} --json_path ./conf/orchestrator/dlt/create-pipeline-prod.json --mode prod

      - name: Job deployment Prod
        run: |
          poetry run dbx deploy --deployment-file=./conf/orchestrator/dbx/deployment.yml.j2 --workflows='dlt-from-remote-prod' --no-package